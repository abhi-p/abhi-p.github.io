---
title: "Rhythms of the Machine: Deep Learning in Music Creationg"
collection: projects
urlslug: "music-gen-ai"
type: "Academic"
#teaserurl: 'https://www.youtube.com/watch?v=1Mg0Z7lUwNM&ab_channel=AbhishekPaul'
#start_time: 547
# demourl: "https://youtu.be/StTqXEQ2l-Y?t=35s" # [![Everything Is AWESOME](https://i.sstatic.net/q3ceS.png)](https://youtu.be/StTqXEQ2l-Y?t=35s "Everything Is AWESOME")
# **Resources:** [[Technical report](https://adivekar-utexas.github.io/files/UTCS-Deep-Learning-Final-Autonomous-agents-for-realtime-multiplayer-ice-hockey.pdf)]

permalink: /projects/2024-11-26-Rhythms-of-the-Machine-Deep-Learning-in-Music-Creation
contributors: "Abhishek Paul"
contribution: "On all aspects of the project"
date: 2024-11-26
reporturl: 'https://abhi-p.github.io/files/Music_Generation_Final_Report.pdf'

# videourl: "https://www.youtube.com/embed/15sa6OeIWJg"
# codeurl: 'https://github.com/ARDivekar/SearchDistribute'
excerpt: "<br /> \
**Project Goal**: This project was an oppertunity to build upon my 2019 Music Generation project. The goal of this porject is to create an application that allows muscians to to create extensions to their input. I created and trained a LSTM-based recurrent neural network designed to model monophonic music with expressive timing and dynamics. Here are a few examples generated by the model:

<audio controls>
    <source src="https://abhi-p.github.io/files/monophonic_rnn/short_extension_1/input_melody_1.mp3" type="audio/mpeg">
    Your browser does not support the audio element.
</audio>


**Outcome:** Our team successfully created a music composition application using neural networks. The framework we developed allows for future enhancements of neural network models for music generation. This framework is adaptable, requiring minimal code changes to use different datasets and alter model parameters for future projects."


---

