---
title: "Music Generation Using Machine Learning"
collection: projects
urlslug: "music-generation"
type: "Academic"
teaserurl: 'https://www.youtube.com/watch?v=1Mg0Z7lUwNM&ab_channel=AbhishekPaul'
start_time: 547
# demourl: "https://youtu.be/StTqXEQ2l-Y?t=35s" # [![Everything Is AWESOME](https://i.sstatic.net/q3ceS.png)](https://youtu.be/StTqXEQ2l-Y?t=35s "Everything Is AWESOME")
# **Resources:** [[Technical report](https://adivekar-utexas.github.io/files/UTCS-Deep-Learning-Final-Autonomous-agents-for-realtime-multiplayer-ice-hockey.pdf)]

permalink: /projects/2019-09-08-music-gneration
contributors: "Abhishek Paul, Romal Peccia, Donald Lleshi"
contribution: "On all aspects of the project"
date: 2017-09-08
# videourl: "https://www.youtube.com/embed/15sa6OeIWJg"
# codeurl: 'https://github.com/ARDivekar/SearchDistribute'
excerpt: "<br /> \
**Project Goal**: The goal of this project was to create a music composition application that utilizes machine learning to generate music extensions. The application allows users to play a melody on a MIDI keyboard, and the system generates a continuation of that melody for the same length of time. <br /> \ <br /> \

**Project Overview:** <br /> \
1) UI: \n <br /> \
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  i) Users are prompted to play a melody on a MIDI keyboard.\n <br /> \
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  ii) The application transforms the input melody using the same transformations applied to the training dataset. \n <br /> \
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  iii) The transformed melody is fed through a trained model to generate a continuation of the played notes.\n <br /> \
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  iv) The user's recording and the model-generated continuation are saved and displayed to the user.\n <br /> \
2) Machine Learning Pipeline:\n <br /> \
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   i) Data Transformation: Developed techniques to convert music into machine-readable embeddings.\n <br /> \
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   ii) Model Development: Designed and trained a Recurrent Neural Network (RNN) for music generation.\n <br /> \
 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;   iii) Integration: Integrated the final model with a user interface and a physical MIDI keyboard.\n <br /> \ <br /> \

**Outcome:** Our team successfully created a music composition application using neural networks. The framework we developed allows for future enhancements of neural network models for music generation. This framework is adaptable, requiring minimal code changes to use different datasets and alter model parameters for future projects."


---

